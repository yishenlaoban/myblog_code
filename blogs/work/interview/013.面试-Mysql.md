---
title: 面试-Mysql
date: 2022-04-28
categories:
 - 面试
tags:
 - Mysql
sidebar: 'auto'
---


## 脑图

<iframe src="https://gitmind.cn/app/doc/4a18296cbd3fa4e56752fadd3b7e557f" width="100%" height="500" frameborder="0" scrolling="No" leftmargin="0" topmargin="0"></iframe>


## 事务隔离级别

### ACID原则

::: danger

- 原子性：事务满足原子性，所有操作要么都执行成功，要么都不执行
- 一致性：事物开始和完成时，数据都必须保持一致状。比如：如果从A账户转账到B账户，不可能A账户扣了钱，而B账户没有加钱
- 隔离性：并发环境中，各事务之间的执行不被其它事务干扰，即不同的并发事务操作相同的数据时，每个事务都有自己的完整数据空间
- 持久性：事务对数据库的操作是写入磁盘，哪怕宕机重新运行也是事务结束后的状态

:::

### Read Uncommitted（读取未提交内容）

在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。

脏读的具体示例如下：

| 时间点 | 事务A               | 事务B          |
| :----- | :------------------ | :------------- |
| 1      | 开启事务            |                |
| 2      |                     | 开启事务       |
| 3      | 查询数据为100条     |                |
| 4      |                     | insert一条数据 |
| 5      | 再查询，结果为101条 |                |

在时间点5，事务A再次查询数据时，事务B并没有提交事务，但是，新的数据也被事务A查出来了。这就是脏读。

### Read Committed（读取提交内容）

这是大多数[数据库](https://cloud.tencent.com/solution/database?from=10680)系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。

| 时间点 | 事务A           | 事务B          |
| :----- | :-------------- | :------------- |
| 1      | 开启事务        |                |
| 2      |                 | 开启事务       |
| 3      | 查询数据为100条 |                |
| 4      |                 | insert一条数据 |
| 5      | 查询数据为100条 |                |
| 6      |                 | 提交事务       |
| 7      | 查询数据为101条 |                |

我们可以看到，事务B在提交事务之前，事务A的两次查询结果是一致的。事务B提交事务以后，事务A再次查询，查询到了新增的这条数据。在事务A中，多次查询的结果不一致，这就是我们说的“不可重复读”。

### Repeatable Read（可重读）

这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。

上面这一段是MySQL官方给出的解释，听着云里雾里。“可重读”这种隔离级别解决了上面例子中的问题，保证了同一事务内，多次查询的结果是一致的。也就是说，事务B插入数据提交事务后，事务A的查询结果也是100条，因为事务A在开启事务时，事务B插入的数据还没有提交。

**但是，这又引出了另外一个情况，“幻读”。**这个幻读我之前理解是有问题的，在面试时，被对方一顿质疑。**现在我们就看看幻读的正确理解：**

| 时间点 | 事务A                  | 事务B          |
| :----- | :--------------------- | :------------- |
| 1      | 开启事务               |                |
| 2      |                        | 开启事务       |
| 3      | 查询数据“张三”，不存在 |                |
| 4      |                        | 插入数据“张三” |
| 5      |                        | 提交事务       |
| 6      | 查询数据“张三”，不存在 |                |
| 7      | 插入数据“张三”，不成功 |                |

**事务A查询“张三”，查询不到，插入又不成功，“张三”这条数据就像幻觉一样出现。这就是所谓的“幻读”**。网上对“幻读”还是其他的解释，都是错误的。**比如像“幻读”和“不可重复读”是一样，只不过“幻读”是针对数据的个数。这些理解都是错误的。**

### Serializable（可串行化）

这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。这种隔离级别很少使用，不给大家做过多的介绍了。



## 索引类别原理相关

::: tip

索引对查询速度有至关重要的影响，理解索引也是进行数据库性能调优的起点，索引就是为了提高数据查询的效率。`索引可以包含一个或多个列的值`，如果索引包含多个列的值，则`列的顺序`也十分重要，因为MySQL只能高效地使用索引的最左前缀列

:::

### 索引类别

#### 哈希索引

::: tip 概念

哈希表是一种以键-值（key-value）的方式存储数据的结构，我们只要输入待查找的值（即key），就可以找到其对应的值（即Value）。哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置，即index = Hash(key)。如果出现哈希冲突，就采用拉链法解决(还有开放定址法：线性或左右平方跳跃)。

因为哈希表中存放的数据不是有序的，因此不适合做区间查询，适用于只有等值查询的场景

:::

#### 有序数组

::: tip 概念

有序数组在等值查询和范围查询场景中的性能都非常优秀。用二分法就可以快速找到（时间复杂度为O(logN)）。但是如果要往中间插入一条数据，则必须挪动后面的所有记录，成本较高。因此，有序数组只适用于静态存储引擎，即数据表一旦建立后不再会修改

:::

#### B+树索引(InnoDB)

> 简单的说，是因为使用B+树存储数据可以让一个查询尽量少的读磁盘，从而减少查询时磁盘I/O的时间。
>
> 在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。每一个索引在 InnoDB 里面对应一棵 B+ 树。

假设，有这样一张表：该表主键为ID，且还有一个字段为k，并在k上有索引。

```sql
CREATE TABLE T( id int primary key,    k int not null,    index (k) )engine=InnoDB;
```

表中有5条记录，分别为R1~R5，(100,1)、(200,2)、(300,3)、(500,5)和(600,6)。则在InnoDB中的索引组织结构是这样的： 

![image-20220425183531187](https://img.yishenlaoban.top/image_my/image-20220425183531187.png)

根据叶子结点的内容，索引类型分为主键索引和非主键索引。

- 主键索引的叶子结点存的是整条记录，主键索引也被称为聚簇索引（clustered index）。

- 非主键索引的叶子结点存的是主键的值，非主键索引也被称为二级索引（secondary index）/普通索引/辅助索引。

那么，基于主键索引和非主键索引的查询有什么区别？

- 如果语句是 select * from T where ID=500，即主键查询，则只需要搜索ID这棵树。

- 如果语句是 select * from T where k=5，即非主键索引查询，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。从非主键索引回到主键索引的过程称为`回表`。

也就是说，`基于非主键索引的查询需要多扫描一棵索引树`。因此，我们在应用中应该尽量使用主键查询。而从存储空间的角度讲，`因为非主键索引树的叶结点存放的是主键的值`，那么，应该考虑让主键的字段尽量短，这样非主键索引的叶子结点就越小，非主键索引占用的空间也就越小。一般情况下，`建议创建一个自增主键，这样非主键索引占用的空间最小`



#### 非聚集索引

**非聚集索引即索引结构和数据分开存放的索引。**

**二级索引属于非聚集索引。**

非聚集索引的叶子节点并不一定存放数据的指针，因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。

:::tip

非聚集索引的优点

:::

**更新代价比聚集索引要小** 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的

:::tip

非聚集索引的缺点

:::

1. 跟聚集索引一样，非聚集索引也依赖于有序的数据
2. **可能会二次查询(回表)** :这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。

这是 MySQL 的表的文件截图:

![img](https://img2022.cnblogs.com/blog/2346254/202205/2346254-20220502110628092-1453963166.png)

聚集索引和非聚集索引:

![img](https://img2022.cnblogs.com/blog/2346254/202205/2346254-20220502110628123-105612666.png)

:::tip

**非聚集索引一定回表查询吗**(覆盖索引)?

:::

**非聚集索引不一定回表查询。**

> 试想一种情况，用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。

```sql
 SELECT name FROM table WHERE name='guang19';
```

> 那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。

**即使是 MYISAM 也是这样，虽然 MYISAM 的主键索引确实需要回表， 因为它的主键索引的叶子节点存放的是指针。但是如果 SQL 查的就是主键呢?**

```sql
SELECT id FROM table WHERE id=1;
```

主键索引本身的 key 就是主键，查到返回就行了。这种情况就称之为覆盖索引了。





> 我们需要搞清楚以下几个问题：
>
> <Badge text="　第一：聚集索引的约束是唯一性，是否要求字段也是唯一的呢？     不要求唯一！"/>
>
> 　　分析：如果认为是的朋友，可能是受系统默认设置的影响，一般我们指定一个表的主键，如果这个表之前没有聚集索引，同时建立主键时候没有强制指定使用非聚集索引，SQL会默认在此字段上创建一个聚集索引，而主键都是唯一的，所以理所当然的认为创建聚集索引的字段也需要唯一。
>
> 　　结论：聚集索引可以创建在任何一列你想创建的字段上，这是从理论上讲，实际情况并不能随便指定，否则在性能上会是恶梦。
>
> <Badge text="　第二：为什么聚集索引可以创建在任何一列上，如果此表没有主键约束，即有可能存在重复行数据呢？"/>　　
>
> 　　粗一看，这还真是和聚集索引的约束相背，但实际情况真可以创建聚集索引。
>
> 　　分析其原因是：如果未使用 UNIQUE 属性创建聚集索引，数据库引擎将向表自动添加一个四字节 uniqueifier 列。必要时，数据库引擎 将向行自动添加一个 uniqueifier 值，使每个键唯一。此列和列值供内部使用，用户不能查看或访问。
>
> 　<Badge text="　　第三：是不是聚集索引就一定要比非聚集索引性能优呢?"/>　
>
> 　　如果想查询学分在60-90之间的学生的学分以及姓名，在学分上创建聚集索引是否是最优的呢？
>
> 　　答：否。既然只输出两列，我们可以在学分以及学生姓名上创建联合非聚集索引，此时的索引就形成了覆盖索引，即索引所存储的内容就是最终输出的数据，这种索引在比以学分为聚集索引做查询性能更好。
>
> <Badge text="　　第四：在数据库中通过什么描述聚集索引与非聚集索引的？"/>　　　
>
> 　　索引是通过二叉树的形式进行描述的，我们可以这样区分聚集与非聚集索引的区别：聚集索引的叶节点就是最终的数据节点，而非聚集索引的叶节仍然是索引节点，但它有一个指向最终数据的指针。
>
> <Badge text="　　第五：在主键是创建聚集索引的表在数据插入上为什么比主键上创建非聚集索引表速度要慢？"/>　　　
>
> 　　有了上面第四点的认识，我们分析这个问题就有把握了，在有主键的表中插入数据行，由于有主键唯一性的约束，所以需要保证插入的数据没有重复。我们来比较下主键为聚集索引和非聚集索引的查找情况：聚集索引由于索引叶节点就是数据页，所以如果想检查主键的唯一性，需要遍历所有数据节点才行，但非聚集索引不同，由于非聚集索引上已经包含了主键值，所以查找主键唯一性，只需要遍历所有的索引页就行（索引的存储空间比实际数据要少），这比遍历所有数据行减少了不少IO消耗。这就是为什么主键上创建非聚集索引比主键上创建聚集索引在插入数据时要快的真正原因。

#### 联合索引

> 联合索引是指对表上的多个列进行索引。下面以一个例子进行说明。假设有下面这样一张表，有这样一个需求，我们需要查询某个用户的购物情况，并按照时间进行排序，取出某用户近几次的购物情况。（注：例子来源于《MySQL技术内幕》）

```sql
# 表
CREATE TABLE buylog(    userid int not null,    buy_date DATE )ENGINE=InnoDB; 
# 插入数据 
insert into buylog values(1, '2019-08-13'); insert into buylog values(2, '2019-08-14'); 
insert into buylog values(3, '2019-08-15'); insert into buylog values(1, '2019-08-11'); 
insert into buylog values(3, '2019-08-10'); insert into buylog values(1, '2019-08-12'); 
# 添加索引 
alter table buylog add index(userid); 
alter table buylog add index(userid, buy_date); 
# （或用key关键字也一样的） 
alter table buylog add key(userid); 
alter table buylog add key(userid, buy_date); 
```

上面的代码建立了两个索引，两个索引都包含了userid字段。

如果只对于userid进行查询，如：

```sql
select * from buylog where userid=2;
```

通过explain查看该语句的执行情况如下：

![image-20220425190520837](https://img.yishenlaoban.top/image_my/image-20220425190520837.png)



可以看到，possible_keys有两个索引可选，一个是`useridandbugdate_index`(两个字段的联合索引)和`userid_index`(userid的单索引)，MySQL最终选择的是联合索引，貌似是版本优化了，走的联合索引，实际上原来是走的单值索引`userid_index`



接着要查询userid=1的最近两次的购买记录，执行的情况：

```sql
EXPLAIN select * from buylog where userid=1 order by buy_date desc limit 2;
```

![image-20220425191150469](https://img.yishenlaoban.top/image_my/image-20220425191150469.png)

> 这一次查询优化器选择的索引(userid, buy_date)联合索引，因为因为在这个联合索引中，`记录已经分别根据userid和buy_date排好序了`，利用这个索引则可以直接取出相应的数据而`无需再对buy_date额外做一次排序操作`了

如果强制使用userid索引，则它的执行计划如下： 

![image-20220425191425941](https://img.yishenlaoban.top/image_my/image-20220425191425941.png)

> 从Extra字段可以看出，该语句的执行需要使用fliesort，也就是需要一次额外的排序操作才能完成查询。显然，这个排序就是对buy_date字段的排序，`因为这里仅使用了userid索引，该索引未对buy_date进行排序`



#### 最左前缀原则

> 对于有很多字段的一张表，查询的方式是多样的，难道要为了每一种可能的查询都定义索引吗？这样岂不是很浪费空间，毕竟建索引也是需要一些空间的。事实上，B+ 树这种索引结构，可以利用索引的“最左前缀”原则来定位记录，避免重复定义索引。

![image-20220425191731541](https://img.yishenlaoban.top/image_my/image-20220425191731541.png)

::: tip

假设建立了一个联合索引(name,age)，可以看到，索引项是按照索引定义里面出现的字段顺序排序的，先根据名字排序，名字相同的就根据年龄排序。

当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。

如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是"where name like '张%'"。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。

可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。`这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符`。

因此，基于最左前缀原则，我们在定义联合索引的时候，考虑如何安排索引内的字段顺序就至关重要了！评估的标准就是索引的复用能力，比如，`当已经有了(a,b)字段的索引，一般就不需要再单独在a上建立索引了`。这里其实可以映射到上面联合索引的例子，为什么第一条SQL只查userid的时候用的还是联合索引

:::



#### 覆盖索引

<Badge text="还是用这张表进行说明"/>

```sql
CREATE TABLE T( id int primary key,    k int not null,    index (k) )engine=InnoDB;
```

如果执行的语句是：

```sql
select * from T where k between 3 and 5
```

则这条SQL执行流程如下：

::: warning

1. 在 k 索引树上找到 k=3 的记录，取得 ID = 300；

2. 再到 ID 索引树查到 ID=300 对应的 R3；

3. 在 k 索引树取下一个值 k=5，取得 ID=500；

4. 再回到 ID 索引树查到 ID=500 对应的 R4；

5. 在 k 索引树取下一个值k=6，不满足条件，循环结束。

:::

> 在这个过程中，回到主键索引树根据ID去查询的过程，称为回表。在这个例子中，`由于查询的结果是所有字段，所需要的数据只有主键上才有，所以不得不回表`。但如果执行的语句是下面这样的，注意！这里查询的结果只是“ID”（恰好是主键），而不是所有字段了。

```sql
select ID from T where k between 3 and 5;
```

> 因为k字段的索引是辅助索引(二级索引)，其根节点上存放的是k字段值和主键值，所以主键ID的值已经在字段k的索引树上了，因此可以直接提供查询结果，不会触发回表，也就是说，在这个查询里，索引k已经"覆盖了"我们的查询需求，故称为覆盖索引



> 除了上面这种情况，针对某些统计问题时，覆盖索引也能发挥用处。还是以上面的例子，执行如下语句来统计表的记录总数（在此我们假设这张表数据量特别特别大，需要多次磁盘IO）：
>
> ```sql
> select count(*) from T;
> ```
>
> 如果没有对字段k设置索引，那么只能是通过聚簇索引来计算；如果对字段k设置了索引，那么，`由于聚簇索引的叶结点存放的是整行记录的所有信息，而辅助索引的叶结点只存放主键`，两者相比，`对于一页内存，显然辅助索引能够存放的节点更多`，意味着辅助索引可以`减少IO次数`，从而更快的计算出count(*)的值。

测试一下：用buylog表，先把userid的单列索引删掉，联合索引也删掉，不然会走联合索引，然后执行SQL

```sql
EXPLAIN select count(*) from buylog;
```

![image-20220425193651140](https://img.yishenlaoban.top/image_my/image-20220425193651140.png)

<Badge text="可以看到，优化器选择主键聚簇索引进行操作"/>



把索引加上后：

![image-20220425193857404](https://img.yishenlaoban.top/image_my/image-20220425193857404.png)

<Badge text="可以看到，优化器选择了单值辅助索引进行操作。如果单值没有，则使用联合索引"/>

> 可见，如果建立了辅助索引，在有些场景下，优化器会自动使用辅助索引从而提升查询效率



::: danger 总结

覆盖索引就是从辅助索引中就能直接得到查询结果，而不需要回表到聚簇索引中进行再次查询，所以可以减少搜索次数（不需要从辅助索引树回表到聚簇索引树），或者说`减少IO操作（通过辅助索引树可以一次性从磁盘载入更多节点）`，从而提升性能

:::



#### 索引下推

> 什么是索引下推（Index Condition Pushdown，ICP）呢？
>
> 假设有这么个需求，查询表中“名字第一个字是张，性别男，年龄为10岁的所有记录”。那么，查询语句是这么写的：
>
> ```sql
> select * from tuser where name like '张 %' and age=10 and ismale=1;
> ```
>
> 根据前面说的“最左前缀原则”，该语句在搜索索引树的时候，只能匹配到名字第一个字是‘张’的记录（即记录ID3），接下来是怎么处理的呢？当然就是从ID3开始，逐个回表，到主键索引上找出相应的记录，再比对age和ismale这两个字段的值是否符合。
>
> 但是！MySQL 5.6引入了索引下推优化，`可以在索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表次数`

下面分别展示这两种情况：

图1：没有索引下推的时候

![image-20220425194338507](https://img.yishenlaoban.top/image_my/image-20220425194338507.png)

图2：有索引下推的时候

![image-20220425194404154](https://img.yishenlaoban.top/image_my/image-20220425194404154.png)

::: tip 注意

图 1 中，在 (name,age) 索引里面特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把"name 第一个字是'张'"的记录一条条取出来回表。因此，需要回表 4 次。

图 2 跟图 1 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。

:::



::: danger 总结

如果没有索引下推优化（或称ICP优化），当进行索引查询时，首先根据索引来查找记录，然后再根据where条件来过滤记录；在支持ICP优化后，MySQL会在取出索引的同时，判断是否可以进行where条件过滤，也就是说提前执行where的部分过滤操作，在某些场景下，可以大大减少回表次数，从而提升整体性能

:::



## 日志

`MySQL` 日志 主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中，比较重要的还要属二进制日志 `binlog`（归档日志）和事务日志 `redo log`（重做日志）和 `undo log`（回滚日志）。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502114235550-1833113107.png)

今天就来聊聊 `redo log`（重做日志）、`binlog`（归档日志）、两阶段提交、`undo log` （回滚日志）。





### redo log

`redo log`（重做日志）是`InnoDB`存储引擎独有的，它让`MySQL`拥有了崩溃恢复能力。

比如 `MySQL` 实例挂了或宕机了，重启时，`InnoDB`存储引擎会使用`redo log`恢复数据，保证数据的持久性与完整性。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502114358140-1569139859.png)

`MySQL` 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 `Buffer Pool` 中。

后续的查询都是先从 `Buffer Pool` 中找，没有命中再去硬盘加载，减少硬盘 `IO` 开销，提升性能。

更新表数据的时候，也是如此，发现 `Buffer Pool` 里存在要更新的数据，就直接在 `Buffer Pool` 里更新。

然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（`redo log buffer`）里，接着刷盘到 `redo log` 文件里。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502114357719-1387158730.png)

> 图片笔误提示：第 4 步 “清空 redo log buffe 刷盘到 redo 日志中”这句话中的 buffe 应该是 buffer。

理想情况，事务一提交就会进行刷盘操作，但实际上，刷盘的时机是根据策略来进行的。

> 小贴士：每条 redo 记录由“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”组成

#### 刷盘时机

`InnoDB` 存储引擎为 `redo log` 的刷盘策略提供了 `innodb_flush_log_at_trx_commit` 参数，它支持三种策略：

- **0** ：设置为 0 的时候，表示每次事务提交时不进行刷盘操作
- **1** ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）
- **2** ：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache

`innodb_flush_log_at_trx_commit` 参数默认为 1 ，也就是说当事务提交时会调用 `fsync` 对 redo log 进行刷盘

另外，`InnoDB` 存储引擎有一个后台线程，每隔`1` 秒，就会把 `redo log buffer` 中的内容写到文件系统缓存（`page cache`），然后调用 `fsync` 刷盘。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502114357691-722007771.png)

也就是说，一个没有提交事务的 `redo log` 记录，也可能会刷盘。

**为什么呢？**

因为在事务执行过程 `redo log` 记录是会写入`redo log buffer` 中，这些 `redo log` 记录会被后台线程刷盘。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502114358931-751765001.png)

除了后台线程每秒`1`次的轮询操作，还有一种情况，当 `redo log buffer` 占用的空间即将达到 `innodb_log_buffer_size` 一半的时候，后台线程会主动刷盘。

下面是不同刷盘策略的流程图。

:::tip

innodb_flush_log_at_trx_commit=0

:::

![img](https://img.yishenlaoban.top/image_my/2346254-20220502114358198-802155618.png)

为`0`时，如果`MySQL`挂了或宕机可能会有`1`秒数据的丢失。

:::tip

innodb_flush_log_at_trx_commit=1

:::

![img](https://img.yishenlaoban.top/image_my/2346254-20220502114358814-1937160169.png)

为`1`时， 只要事务提交成功，`redo log`记录就一定在硬盘里，不会有任何数据丢失。

如果事务执行期间`MySQL`挂了或宕机，这部分日志丢了，但是事务并没有提交，所以日志丢了也不会有损失。



:::tip

innodb_flush_log_at_trx_commit=2

:::

![img](https://img.yishenlaoban.top/image_my/2346254-20220502114357825-51141401.png)

为`2`时， 只要事务提交成功，`redo log buffer`中的内容只写入文件系统缓存（`page cache`）。

如果仅仅只是`MySQL`挂了不会有任何数据丢失，但是宕机可能会有`1`秒数据的丢失。





### binlog

`redo log` 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 `InnoDB` 存储引擎。

而 `binlog` 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于`MySQL Server` 层。

不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog` 日志。

那 `binlog` 到底是用来干嘛的？

可以说`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654280-1924732317.png)

`binlog`会记录所有涉及更新数据的逻辑操作，并且是顺序写。

:::tip

记录格式

:::

`binlog` 日志有三种格式，可以通过`binlog_format`参数指定。

- **statement**
- **row**
- **mixed**

指定`statement`，记录的内容是`SQL`语句原文，比如执行一条`update T set update_time=now() where id=1`，记录的内容如下。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654244-866589880.png)

同步数据时，会执行记录的`SQL`语句，但是有个问题，`update_time=now()`这里会获取当前系统时间，直接执行会导致与原库的数据不一致。

为了解决这种问题，我们需要指定为`row`，记录的内容不再是简单的`SQL`语句了，还包含操作的具体数据，记录内容如下。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654237-1729711991.png)

`row`格式记录的内容看不到详细信息，要通过`mysqlbinlog`工具解析出来。

`update_time=now()`变成了具体的时间`update_time=1627112756247`，条件后面的@1、@2、@3 都是该行数据第 1 个~3 个字段的原始值（**假设这张表只有 3 个字段**）。

这样就能保证同步数据的一致性，通常情况下都是指定为`row`，这样可以为数据库的恢复与同步带来更好的可靠性。

但是这种格式，需要更大的容量来记录，比较占用空间，恢复与同步时会更消耗`IO`资源，影响执行速度。

所以就有了一种折中的方案，指定为`mixed`，记录的内容是前两者的混合。

`MySQL`会判断这条`SQL`语句是否可能引起数据不一致，如果是，就用`row`格式，否则就用`statement`格式。





:::tip

写入机制

:::

`binlog`的写入时机也非常简单，事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。

因为一个事务的`binlog`不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为`binlog cache`。

我们可以通过`binlog_cache_size`参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（`Swap`）。

`binlog`日志刷盘流程如下

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654259-280995113.png)

- **上图的 write，是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快**
- **上图的 fsync，才是将数据持久化到磁盘的操作**

`write`和`fsync`的时机，可以由参数`sync_binlog`控制，默认是`0`。

为`0`的时候，表示每次提交事务都只`write`，由系统自行判断什么时候执行`fsync`。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654352-1184620837.png)

虽然性能得到提升，但是机器宕机，`page cache`里面的 binlog 会丢失。

为了安全起见，可以设置为`1`，表示每次提交事务都会执行`fsync`，就如同 **redo log 日志刷盘流程** 一样。

最后还有一种折中方式，可以设置为`N(N>1)`，表示每次提交事务都`write`，但累积`N`个事务后才`fsync`。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654365-1202352670.png)

在出现`IO`瓶颈的场景里，将`sync_binlog`设置成一个比较大的值，可以提升性能。

同样的，如果机器宕机，会丢失最近`N`个事务的`binlog`日志。



### 两阶段提交



`redo log`（重做日志）让`InnoDB`存储引擎拥有了崩溃恢复能力。

`binlog`（归档日志）保证了`MySQL`集群架构的数据一致性。

虽然它们都属于持久化的保证，但是侧重点不同。

在执行更新语句过程，会记录`redo log`与`binlog`两块日志，以基本的事务为单位，`redo log`在事务执行过程中可以不断写入，而`binlog`只有在提交事务时才写入，所以`redo log`与`binlog`的写入时机不一样。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654476-1428500115.png)

回到正题，`redo log`与`binlog`两份日志之间的逻辑不一致，会出现什么问题？

我们以`update`语句为例，假设`id=2`的记录，字段`c`值是`0`，把字段`c`值更新成`1`，`SQL`语句为`update T set c=1 where id=2`。

假设执行过程中写完`redo log`日志后，`binlog`日志写期间发生了异常，会出现什么情况呢？

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654416-1205722610.png)

由于`binlog`没写完就异常，这时候`binlog`里面没有对应的修改记录。因此，之后用`binlog`日志恢复数据时，就会少这一次更新，恢复出来的这一行`c`值是`0`，而原库因为`redo log`日志恢复，这一行`c`值是`1`，最终数据不一致。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654391-1733457382.png)

为了解决两份日志之间的逻辑一致问题，`InnoDB`存储引擎使用**两阶段提交**方案。

原理很简单，将`redo log`的写入拆成了两个步骤`prepare`和`commit`，这就是**两阶段提交**。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654532-1357734665.png)

使用**两阶段提交**后，写入`binlog`时发生异常也不会有影响，因为`MySQL`根据`redo log`日志恢复数据时，发现`redo log`还处于`prepare`阶段，并且没有对应`binlog`日志，就会回滚该事务。

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654544-938826646.png)

再看一个场景，`redo log`设置`commit`阶段发生异常，那会不会回滚事务呢？

![img](https://img.yishenlaoban.top/image_my/2346254-20220502121654596-52116350.png)

并不会回滚事务，它会执行上图框住的逻辑，虽然`redo log`是处于`prepare`阶段，但是能通过事务`id`找到对应的`binlog`日志，所以`MySQL`认为是完整的，就会提交事务恢复数据。



###  undo log

> 这部分内容为 JavaGuide 的补充：

我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行**回滚**，在 MySQL 中，恢复机制是通过 **回滚日志（undo log）** 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 **回滚日志** 中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。

另外，`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改

### 总结

MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。

`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。





## MVCC(多版本并发控制)

### 快照读

:::tip

对于 [一致性非锁定读（Consistent Nonlocking Reads）](https://dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html)的实现，通常做法是加一个`版本号`或者`时间戳字段`，在更新数据的同时版本号 + 1 或者更新时间戳。查询时，将当前可见的版本号与对应记录的版本号进行比对，如果记录的版本小于可见版本，则表示该记录可见;

在InnoDB引擎中，[多版本控制 (multi versioning)open in new window）](https://dev.mysql.com/doc/refman/5.7/en/innodb-multi-versioning.html) 就是对非锁定读的实现。如果读取的行正在执行 `DELETE` 或 `UPDATE` 操作，这时**读取操作不会去等待行上锁的释放**。相反地，`InnoDB` 存储引擎会去读取行的一个快照数据，对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)

在 `Repeatable Read` 和 `Read Committed` 两个隔离级别下，如果是执行普通的 `select` 语句（不包括 `select ... lock in share mode` ,`select ... for update`）则会使用 `一致性非锁定读（MVCC）`。并且在 `Repeatable Read` 下 `MVCC` 实现了可重复读和防止部分幻读

:::



### 锁定读

如果执行的是下列语句，就是 [**锁定读（Locking Reads）**](https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-reads.html)

:::tip

> - `select ... lock in share mode`
> - `select ... for update`
> - `insert`、`update`、`delete` 操作

锁定读的数据的最新版本，这个也叫`当前读`。锁定读会对读取到的记录加锁。

> - `select ... lock in share mode`：对记录加 `S` 锁，其它事务也可以加`S`锁，如果加 `x` 锁则会被阻塞
> - `select ... for update`、`insert`、`update`、`delete`：对记录加 `X` 锁，且其它事务不能加任何锁

:::

:::danger 比较

在一致性非锁定读下，即使读取的记录已被其它事务加上 `X` 锁，这时记录也是可以被读取的，即读取的快照数据。上面说了，在 `Repeatable Read` 下 `MVCC` 防止了部分幻读，这边的 “部分” 是指在 `一致性非锁定读` 情况下，只能读取到第一次查询之前所插入的数据（根据 Read View 判断数据可见性，Read View 在第一次查询时生成）。但是！如果是 `当前读` ，每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。所以， **`InnoDB` 在实现`Repeatable Read` 时，如果执行的是当前读，则会对读取的记录使用 `Next-key Lock` ，来防止其它事务在间隙间插入数据**

:::

### InnoDB 对 MVCC 的实现

`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View(一致性视图)` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改



### 隐藏字段

在内部，`InnoDB` 存储引擎为每行数据添加了三个 [隐藏字段open in new window](https://dev.mysql.com/doc/refman/5.7/en/innodb-multi-versioning.html)：

- `DB_TRX_ID（6字节）`：表示最后一次插入或更新该行的事务 id。此外，`delete` 操作在内部被视为更新，只不过会在记录头 `Record header` 中的 `deleted_flag` 字段将其标记为已删除
- `DB_ROLL_PTR（7字节）` 回滚指针，指向该行的 `undo log` 。如果该行未被更新，则为空
- `DB_ROW_ID（6字节）`：如果没有设置主键且该表没有唯一非空索引时，`InnoDB` 会使用该 id 来生成聚簇索引





### undo-log

`undo log` 主要有两个作用：

- 当事务回滚时用于将数据恢复到修改前的样子
- 另一个作用是 `MVCC` ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 `undo log` 读取之前的版本数据，以此实现非锁定读

**在 `InnoDB` 存储引擎中 `undo log` 分为两种： `insert undo log` 和 `update undo log`：**

1. **`insert undo log`** ：指在 `insert` 操作中产生的 `undo log`。因为 `insert` 操作的记录只对事务本身可见，对其他事务不可见，故该 `undo log` 可以在事务提交后直接删除。不需要进行 `purge` 操作

**`insert` 时的数据初始状态：**

![img](https://img.yishenlaoban.top/image_my/2346254-20220502134403257-1017798639.png)

1. **`update undo log`** ：`update` 或 `delete` 操作中产生的 `undo log`。该 `undo log`可能需要提供 `MVCC` 机制，因此不能在事务提交时就进行删除。提交时放入 `undo log` 链表，等待 `purge线程` 进行最后的删除

**数据第一次被修改时：**

![img](https://img.yishenlaoban.top/image_my/2346254-20220502134403326-1824275947.png)

**数据第二次被修改时：**

![img](https://img.yishenlaoban.top/image_my/2346254-20220502134403344-1420760830.png)

不同事务或者相同事务的对同一记录行的修改，会使该记录行的 `undo log` 成为一条链表，链首就是最新的记录，链尾就是最早的旧记录。

### ReadView

::: tip 概念

​	Read View 就是事务进行快照读操作的时候生产的读视图 (Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的 ID (当每个事务开启时，都会被分配一个 ID , 这个 ID 是递增的，所以最新的事务，ID 值越大)

​	所以我们知道 Read View 主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个 Read View 读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。

​	ReadView一致性视图主要是由两部分组成：所有**未提交事务的ID数组**和**已经创建的最大事务ID**组成（实际上ReadView还有其他的字段，但不影响这里对MVCC的讲解）。比如：[100,200],300。事务100和200是当前未提交的事务，而事务300是当前创建的最大事务（已经提交了）。

:::



> Read View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的 DB_TRX_ID（`即当前事务 ID`）取出来，与系统当前其他活跃事务的 ID 去对比（由 Read View 维护），如果 DB_TRX_ID 跟 Read View 的属性做了某些比较，不符合可见性，那就通过 DB_ROLL_PTR 回滚指针去取出 Undo Log 中的 DB_TRX_ID 再比较，即遍历链表的 DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的 DB_TRX_ID , 那么这个 DB_TRX_ID 所在的旧记录就是当前事务能看见的最新老版本



### 查询步骤

:::tip

因为ReadView 维护了 `当前正在活跃的未提交事务的id数组`、`未提交事务的最小id`  :mid_id(**在这个id之前的事务，都是已提交的**)、`已创建的最大事务id`:max_id。

> 1. 当前事务去查询的是，如果查询的那条记录的被最近的一次被操作的事务满足`id<min_id`，或者id等于当前执行查询的事务的id，证明该条记录是早已提交的(或是当前事务自己修改的)，所以在读已提交和可重复读的隔离级别中对于当前事务是可见的；
> 2. 如果最近一次被操作的事务id满足`min_id<=id<=max_id`，就要看当前未提交的事务id数组里面有没有这个最近一次操作的事务id，如果有，`证明该版本的记录操作未提交`，所以对当前这个执行查询的事务是不可见的；如果没有在数组中，`表示查到的这次记录操作已经提交了`，对当前这个执行查询的事务是可见的。
> 3. 如果最近一次被操作的事务id满足`id>max_id`，证明这次操作`由将来启动(此时未启动)的事务执行并提交的`，所以对当前这个执行查询的事务是不可见的。
> 4. 最后，还要确保满足以上要求的可访问版本的数据的delete_flag不为true，否则查询到的就会是删除的数据。
> 5. 以上四步执行完后，如果结果是不可见，那么就`通过DB_ROLL_PTR回滚指针继续查询undo log里这条记录的版本链中的下一个版本`并重复以上步骤(因为一开始肯定是查询的最近版本，就是链表头结点)，直到找到可见的记录或者将版本链查询完。

:::

### MVCC➕Next-key-Lock 防止幻读

`InnoDB`存储引擎在 RR 级别下通过 `MVCC`和 `Next-key Lock` 来解决幻读问题：

**1、执行普通 `select`，此时会以 `MVCC` 快照读的方式读取数据**

在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 `Read View` ，并使用至事务提交。所以在生成 `Read View` 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”

**2、执行 select...for update/lock in share mode、insert、update、delete 等当前读**

在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！`InnoDB` 使用 [Next-key Lockopen in new window](https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html#innodb-next-key-locks) 来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读







## 各种锁

### 属性锁

##### 共享锁(Share Lock)

> 共享锁又称读锁，简称S锁。当一个事务对数据加上读锁之后，其他事务只能对该数据加读锁，而无法对数据加写锁，要直到所有读锁释放之后其他事务才能对其加写锁。加了共享锁之后，无法再加排它锁，这就可以避免读取数据时数据被其他事务修改，从而导致不可重复读问题

##### 排它锁(eXclusive Lock)

> 排他锁又称写锁，简称X锁；当一个事务对数据加上写锁之后，其他事务将不能再为数据加任何锁，直到该锁释放之后，其他事务才能对数据进行加锁。加了排他锁之后，其它事务就无法再对加了锁的数据进行读取和修改，所以也就出现脏写和脏读的问题。

### 粒度锁

##### 表锁

> 表锁是指上锁的时候锁住的是整个表，当下一个事务访问该表的时候，必须等前一个事务释放了锁才能进行对表进行访问；

<Badge text="特点： 粒度大，加锁简单，容易冲突"/>

##### 行锁(Record Lock)

> 行锁是对所有行级别锁的一个统称，比如下面说的记录锁、间隙锁、临键锁都是属于行锁， 行锁是指加锁的时候锁住的是表的某一行或多行记录，多个事务访问同一张表时，只有被锁住的记录不能访问，其他的记录可正常访问；

<Badge text="特点：粒度小，加锁比表锁麻烦，不容易冲突，相比表锁支持的并发要高"/>

##### 记录锁

> 记录锁属于行锁中的一种，记录锁的范围只是表中的某一条记录，记录锁是说事务在加锁后锁住的只是表的某一条记录

**触发条件**：<Badge text="精准条件命中，并且命中索引" type="error"/>

**记录锁的作用**：`加了记录锁之后数据可以避免数据在查询的时候被修改的重复读问题，也避免了在修改的事务未提交前被其他事务读取的脏读问题`

<Badge text="记录锁是加在索引上的!" type="warning"/>

##### 间隙锁(Gap Lock)

> 间隙锁属于行锁中的一种，间隙锁是在事务加锁后其锁住的是表记录的某一个区间，当表的相邻ID之间出现空隙则会形成一个区间，遵循左开右闭原则。

**触发条件**：<Badge text="范围查询，查询条件必须命中索引、间隙锁只会出现在REPEATABLE_READ（可重复读)的事务隔离级别中" type="error"/>



例如：

```sql
select * from user where id > 5 and id < 8
#这里id是主键索引，如果数据表中并没有5<id<8的数据，sql查不到记录，就会使用间隙锁将id满足查询的所有数据都锁起来，
#且不管id在这区间的是否存在数据，这样会使得如果没有数据，但是要插入一个id=6的数据，会被阻塞
```

<Badge text="间隙锁是加在索引之间的!" type="warning"/>

**间隙锁作用**：`防止幻读问题。事务并发的时候，如果没有间隙锁，别的事务就能插入间隙之间的数据，造成幻读问题，比如上例中插入id=6的数据`

##### 临键锁(Next-Key Lock)

> 临键锁也属于行锁的一种，并且它是Innodb引擎的行锁默认方式(`所以仅在默认隔离级别，可重复读RR中存在，如果改为读已提交RC，会失效`)，总的来说它就是`记录锁和间隙锁的组合`，临键锁会把查询出来的记录锁住，同时也会把该范围查询内的所有间隙空间也会锁住，再之它会把相邻的下一个区间也会锁住



例如：

| id   | name | age  |
| ---- | ---- | ---- |
| 1    | a    | 18   |
| 5    | b    | 18   |
| 10   | c    | 18   |
| 15   | d    | 18   |

```sql
select * from user_info where id>1 and id<13 for update ;
```

> 上面的SQL执行后，会锁住id=5和id=10的这两行数据，并会锁住1-5，5-10,10-15这三个间隙。
>
> 在不命中的情况下，会退化为间隙锁；命中多条即像上句一样，进行范围锁定

**临键锁的作用**：`结合记录锁和间隙锁的特性，避免了在范围查询时出现脏读、重复读、幻读问题。加了临键锁之后，在范围区间内数据不允许被修改和插入`



### 状态锁

> 状态锁包括意向共享锁和意向排它锁，把他们区分为状态锁的一个核心逻辑，是因为这两个锁都是都是描述是否可以对某一个表进行加表锁的状态

##### 意向锁

> 当一个事务试图对**整个表**进行加锁（共享锁或排它锁）之前，首先需要获得对应类型的意向锁（意向共享锁或意向共享锁）

##### 意向共享锁

> 当一个事务试图对**整个表**进行加共享锁之前，首先需要获得这个表的意向共享锁

##### 意向排它锁

> 当一个事务试图对**整个表**进行加排它锁之前，首先需要获得这个表的意向排它锁

##### 举例：

> ```sql
> update user set name = '李四' where id = 200;
> ```
>
> 线程1执行上述SQL后，对id=5的记录加锁了
>
> ```sql
> update user set name = '张三'
> ```
>
> 这时候线程2想要执行上述SQL，要对全表进行修改，即需要对全表进行加锁，因为是加排它锁，所以要对表进行检查，看有没有被其他事务锁住，所以需要遍历每个索引结点，直到找到id=200的结点被锁住了，才停下，否则会全表扫描，过于耗费时间和损耗数据库性能。

 

**所以就有了意向锁的概念**：`如果事务A加锁成功后就设置一个状态告诉别的事务，我加了个共享锁/排他锁，后面的事务就能够直接知道自己是否能够对表进行加锁，而不用去扫描全表判断表是否已被加锁`。

